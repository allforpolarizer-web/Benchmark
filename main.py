"""
ä¸»æ§åˆ¶æµç¨‹
"""
# -*- coding: utf-8 -*-
import os
import sys
# è®¾ç½®æ§åˆ¶å°ç¼–ç ä¸ºUTF-8
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        pass
from pipeline.sampler import Sampler
from pipeline.prompt import PromptGenerator
from pipeline.preprocess import EnvironmentManager
from pipeline.inference import InferenceEngine
from pipeline.postprocess import PostProcessor


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ç»“æ„åˆ†æåŠ©æ‰‹ Benchmark")
    print("=" * 60)
    
    # è·å–APIå¯†é’¥
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âŒ é”™è¯¯: æœªè®¾ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡: set GEMINI_API_KEY=your-api-key (Windows)")
        return
    
    try:
        # 1. ç”Ÿæˆè¯„æµ‹è®¡åˆ’
        print("\n[1/4] ç”Ÿæˆè¯„æµ‹è®¡åˆ’...")
        sampler = Sampler()
        plan = sampler.generate_plan()
        run_count = sampler.get_run_count()
        total_tasks = len(plan)

        if total_tasks == 0:
            print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ç»“æ„æˆ–æ„å›¾ç»„åˆï¼Œç»“æŸæµç¨‹ã€‚")
            return

        print(f"âœ… è®¡åˆ’ç”Ÿæˆå®Œæˆ: å…± {total_tasks} ä¸ªä»»åŠ¡ï¼Œæ¯ä¸ªç»„åˆç”Ÿæˆ {run_count} æ¬¡ã€‚")

        # 2. åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        print("\n[2/4] åˆå§‹åŒ–LLMå®¢æˆ·ç«¯...")
        prompt_generator = PromptGenerator(api_key=api_key)
        inference_engine = InferenceEngine(api_key=api_key)
        post_processor = PostProcessor(api_key=api_key)
        print("âœ… LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

        # 3. é¢„å¤„ç†ï¼šæ£€æŸ¥openseespyç¯å¢ƒ
        print("\n[3/4] æ£€æŸ¥OpenSeesPyç¯å¢ƒ...")
        env_manager = EnvironmentManager()
        env_manager.setup_environment()
        print("âœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ")

        # 4. æ‰§è¡Œè¯„æµ‹ä»»åŠ¡
        print("\n[4/4] å¼€å§‹æ‰§è¡Œè¯„æµ‹ä»»åŠ¡...")
        report_paths = []

        for idx, (structure, intention, run_index) in enumerate(plan, start=1):
            print("\n" + "-" * 60)
            print(f"ä»»åŠ¡ {idx}/{total_tasks}: {structure}-{intention} (ç¬¬ {run_index} æ¬¡)")
            print("-" * 60)

            try:
                prompt = prompt_generator.generate(intention, structure)
                inference_result = inference_engine.run(prompt, structure, intention, run_index)
                report_path = post_processor.evaluate(inference_result)
                report_paths.append(report_path)
            except Exception as task_error:
                print(f"âŒ ä»»åŠ¡ {idx} å¤±è´¥: {task_error}")
                continue

        print("\n" + "=" * 60)
        print("âœ… Benchmark å®Œæˆï¼")
        if report_paths:
            print("ğŸ“Š ç”Ÿæˆçš„è¯„æµ‹æŠ¥å‘Š:")
            for path in report_paths:
                print(f"  - {path}")
        else:
            print("âš ï¸ æ²¡æœ‰æˆåŠŸç”Ÿæˆè¯„æµ‹æŠ¥å‘Š")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return


if __name__ == "__main__":
    main()

